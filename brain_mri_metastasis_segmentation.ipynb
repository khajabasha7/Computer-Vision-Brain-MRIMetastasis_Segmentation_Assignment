{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "866a409b",
   "metadata": {},
   "source": [
    "# Brain MRI Metastasis Segmentation Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dfbbdb",
   "metadata": {},
   "source": [
    "### Step 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15651a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load MRI images and corresponding masks\n",
    "def load_data(image_dir, mask_dir):\n",
    "    images = []\n",
    "    masks = []\n",
    "    for img_name in os.listdir(image_dir):\n",
    "        img_path = os.path.join(image_dir, img_name)\n",
    "        mask_path = os.path.join(mask_dir, img_name)  # Assuming masks have the same names\n",
    "\n",
    "        # Skip images without masks or vice versa\n",
    "        if os.path.exists(mask_path):\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # CLAHE for enhancing image contrast\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "            img = clahe.apply(img)\n",
    "\n",
    "            images.append(img)\n",
    "            masks.append(mask)\n",
    "    \n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Normalization and augmentation (simplified)\n",
    "def normalize_augment(images, masks):\n",
    "    images = images / 255.0  # Normalize to range [0, 1]\n",
    "    # Data augmentation (rotation, flipping, etc.) can be applied here if necessary\n",
    "    return images, masks\n",
    "\n",
    "# Load and split dataset\n",
    "image_dir = '/content/images'\n",
    "mask_dir = '/content/masks'\n",
    "images, masks = load_data(image_dir, mask_dir)\n",
    "images, masks = normalize_augment(images, masks)\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3c11be",
   "metadata": {},
   "source": [
    "### Step 2: Model Implementation (Nested U-Net and Attention U-Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c483c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def inceptionv3_unet(input_size=(256, 256, 3)):\n",
    "    # Load pre-trained InceptionV3, excluding the top layer\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_size)\n",
    "\n",
    "    # Freeze the pre-trained layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    inputs = layers.Input(shape=input_size)\n",
    "    \n",
    "    # Use InceptionV3 as the encoder part of U-Net\n",
    "    x = base_model(inputs)\n",
    "    \n",
    "    # Add U-Net decoder part here (up-sampling layers)\n",
    "    conv1 = layers.Conv2D(256, 3, activation='relu', padding='same')(x)\n",
    "    up1 = layers.UpSampling2D(size=(2, 2))(conv1)\n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(up1)\n",
    "    up2 = layers.UpSampling2D(size=(2, 2))(conv2)\n",
    "    conv3 = layers.Conv2D(64, 3, activation='relu', padding='same')(up2)\n",
    "    up3 = layers.UpSampling2D(size=(2, 2))(conv3)\n",
    "    \n",
    "    # Final convolution to get a single channel for segmentation\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(up3)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Instantiate the InceptionV3-based U-Net\n",
    "inception_unet_model = inceptionv3_unet()\n",
    "inception_unet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1796790f",
   "metadata": {},
   "source": [
    "### Step 3: Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c84fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "def dice_score(y_true, y_pred):\n",
    "    smooth = 1.0\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "\n",
    "# Train U-Net++\n",
    "unetpp_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate U-Net++\n",
    "y_pred = unetpp_model.predict(X_test)\n",
    "dice_unetpp = dice_score(y_test, y_pred)\n",
    "\n",
    "# Train Attention U-Net\n",
    "att_unet_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate Attention U-Net\n",
    "y_pred_att = att_unet_model.predict(X_test)\n",
    "dice_att = dice_score(y_test, y_pred_att)\n",
    "\n",
    "# Compare the models\n",
    "print(f\"Nested U-Net DICE Score: {dice_unetpp}\")\n",
    "print(f\"Attention U-Net DICE Score: {dice_att}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5800760",
   "metadata": {},
   "source": [
    "### Step 4: Web Application (FAST API Backend & Streamlit UI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b3d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAST API Backend Code\n",
    "\n",
    "from fastapi import FastAPI, UploadFile\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/predict/\")\n",
    "async def predict(file: UploadFile):\n",
    "    image = np.array(Image.open(file.file).convert('L'))\n",
    "    # Preprocess and predict using your trained model\n",
    "    prediction = unetpp_model.predict(image)  # Replace with your model of choice\n",
    "    return {\"segmentation\": prediction.tolist()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1721a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit UI Code\n",
    "\n",
    "import streamlit as st\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "st.title(\"Brain MRI Metastasis Segmentation\")\n",
    "uploaded_file = st.file_uploader(\"Upload a Brain MRI Image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    img = Image.open(uploaded_file)\n",
    "    st.image(img, caption=\"Uploaded MRI.\", use_column_width=True)\n",
    "    \n",
    "    # Send image to backend API for segmentation\n",
    "    response = requests.post(\"http://localhost:8000/predict/\", files={\"file\": uploaded_file})\n",
    "    if response.status_code == 200:\n",
    "        segmentation = response.json()[\"segmentation\"]\n",
    "        st.image(segmentation, caption=\"Metastasis Segmentation\", use_column_width=True)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
